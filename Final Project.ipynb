{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## Predicting Physical Activity from Accelerometer Data\n",
    "\n",
    "In the final project for this course, we are given a set of training data (train_time_series.csv) and corresponding labels (train_labels.csv). The data contain timestamps, UTC time, accuracy, and x, y, and z acceleration columns, and the labels consist of one of four classes (standing, walking, stairs down, and stairs up for 1 to 4, respectively) for every tenth observation of the training data. \n",
    "\n",
    "The goal of the project is to classify different physical activities with optimal accuracy. Test data is included in test_time_series.csv but the corresponding labels are unknown. Given that unverified users do not have access to the true test results, final model accuracy can only be assessed on the training data. Code run time will also be recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20586</td>\n",
       "      <td>1565109930787</td>\n",
       "      <td>2019-08-06T16:45:30.787</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.934860</td>\n",
       "      <td>-0.069046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20587</td>\n",
       "      <td>1565109930887</td>\n",
       "      <td>2019-08-06T16:45:30.887</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.066467</td>\n",
       "      <td>-1.015442</td>\n",
       "      <td>0.089554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20588</td>\n",
       "      <td>1565109930987</td>\n",
       "      <td>2019-08-06T16:45:30.987</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.043488</td>\n",
       "      <td>-1.021255</td>\n",
       "      <td>0.178467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20589</td>\n",
       "      <td>1565109931087</td>\n",
       "      <td>2019-08-06T16:45:31.087</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.987701</td>\n",
       "      <td>0.068985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20590</td>\n",
       "      <td>1565109931188</td>\n",
       "      <td>2019-08-06T16:45:31.188</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.054031</td>\n",
       "      <td>-1.003616</td>\n",
       "      <td>0.126450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>24325</td>\n",
       "      <td>1565110305638</td>\n",
       "      <td>2019-08-06T16:51:45.638</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>-0.710709</td>\n",
       "      <td>0.030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>24326</td>\n",
       "      <td>1565110305738</td>\n",
       "      <td>2019-08-06T16:51:45.738</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.487228</td>\n",
       "      <td>-1.099136</td>\n",
       "      <td>-0.015213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>24327</td>\n",
       "      <td>1565110305838</td>\n",
       "      <td>2019-08-06T16:51:45.838</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.369446</td>\n",
       "      <td>-0.968506</td>\n",
       "      <td>0.036713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>24328</td>\n",
       "      <td>1565110305939</td>\n",
       "      <td>2019-08-06T16:51:45.939</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.167877</td>\n",
       "      <td>-0.802826</td>\n",
       "      <td>0.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>24329</td>\n",
       "      <td>1565110306039</td>\n",
       "      <td>2019-08-06T16:51:46.039</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>-0.991043</td>\n",
       "      <td>0.034973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3744 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      timestamp                 UTC time accuracy         x  \\\n",
       "0          20586  1565109930787  2019-08-06T16:45:30.787  unknown -0.006485   \n",
       "1          20587  1565109930887  2019-08-06T16:45:30.887  unknown -0.066467   \n",
       "2          20588  1565109930987  2019-08-06T16:45:30.987  unknown -0.043488   \n",
       "3          20589  1565109931087  2019-08-06T16:45:31.087  unknown -0.053802   \n",
       "4          20590  1565109931188  2019-08-06T16:45:31.188  unknown -0.054031   \n",
       "...          ...            ...                      ...      ...       ...   \n",
       "3739       24325  1565110305638  2019-08-06T16:51:45.638  unknown  0.024384   \n",
       "3740       24326  1565110305738  2019-08-06T16:51:45.738  unknown  0.487228   \n",
       "3741       24327  1565110305838  2019-08-06T16:51:45.838  unknown  0.369446   \n",
       "3742       24328  1565110305939  2019-08-06T16:51:45.939  unknown  0.167877   \n",
       "3743       24329  1565110306039  2019-08-06T16:51:46.039  unknown  0.689346   \n",
       "\n",
       "             y         z  \n",
       "0    -0.934860 -0.069046  \n",
       "1    -1.015442  0.089554  \n",
       "2    -1.021255  0.178467  \n",
       "3    -0.987701  0.068985  \n",
       "4    -1.003616  0.126450  \n",
       "...        ...       ...  \n",
       "3739 -0.710709  0.030304  \n",
       "3740 -1.099136 -0.015213  \n",
       "3741 -0.968506  0.036713  \n",
       "3742 -0.802826  0.049805  \n",
       "3743 -0.991043  0.034973  \n",
       "\n",
       "[3744 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "train_X = pd.read_csv('train_time_series.csv')\n",
    "train_Y = pd.read_csv('train_labels.csv')\n",
    "test_X = pd.read_csv('test_time_series.csv')\n",
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first look at some of the available columns. The accuracy for each sample is listed as 'unknown,' and the first, unnamed column should merely serve as an index, which Pandas already provides us. We can confirm this latter point by checking that the difference between the Pandas-assigned index column and the input index column is constant. Therefore, we can reduce this dataframe to the usable columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_X.accuracy == 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_X['Unnamed: 0'] - train_X.index == 20586)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the UTC time column should not provide any extra information beyond the timestamp column. To confirm this, we convert the UTC time string to a datetime object, and convert it to the number of seconds since 1/1/1970, which is identical to the timestamp entry for each sample after converting to milliseconds. Thus, we can remove this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = [datetime.strptime(t, '%Y-%m-%dT%H:%M:%S.%f') for t in train_X['UTC time']]\n",
    "sec = [((dti - datetime(1970,1,1)).total_seconds()) for dti in dt]\n",
    "sum(sec[i] * 1000 != train_X.timestamp[i] for i in range(len(dt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565109930787</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.934860</td>\n",
       "      <td>-0.069046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565109930887</td>\n",
       "      <td>-0.066467</td>\n",
       "      <td>-1.015442</td>\n",
       "      <td>0.089554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565109930987</td>\n",
       "      <td>-0.043488</td>\n",
       "      <td>-1.021255</td>\n",
       "      <td>0.178467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565109931087</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.987701</td>\n",
       "      <td>0.068985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565109931188</td>\n",
       "      <td>-0.054031</td>\n",
       "      <td>-1.003616</td>\n",
       "      <td>0.126450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>1565110305638</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>-0.710709</td>\n",
       "      <td>0.030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>1565110305738</td>\n",
       "      <td>0.487228</td>\n",
       "      <td>-1.099136</td>\n",
       "      <td>-0.015213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>1565110305838</td>\n",
       "      <td>0.369446</td>\n",
       "      <td>-0.968506</td>\n",
       "      <td>0.036713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>1565110305939</td>\n",
       "      <td>0.167877</td>\n",
       "      <td>-0.802826</td>\n",
       "      <td>0.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>1565110306039</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>-0.991043</td>\n",
       "      <td>0.034973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3744 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp         x         y         z\n",
       "0     1565109930787 -0.006485 -0.934860 -0.069046\n",
       "1     1565109930887 -0.066467 -1.015442  0.089554\n",
       "2     1565109930987 -0.043488 -1.021255  0.178467\n",
       "3     1565109931087 -0.053802 -0.987701  0.068985\n",
       "4     1565109931188 -0.054031 -1.003616  0.126450\n",
       "...             ...       ...       ...       ...\n",
       "3739  1565110305638  0.024384 -0.710709  0.030304\n",
       "3740  1565110305738  0.487228 -1.099136 -0.015213\n",
       "3741  1565110305838  0.369446 -0.968506  0.036713\n",
       "3742  1565110305939  0.167877 -0.802826  0.049805\n",
       "3743  1565110306039  0.689346 -0.991043  0.034973\n",
       "\n",
       "[3744 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X.iloc[:, [1, 4, 5, 6]]\n",
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our reduced dataframe, we can begin to train our algorithm. We can test a number of different classification algorithms, but will restrict ourselves to those covered in this course, i.e. multi-class logistic regression and a random forest classifier. Support vector classifiers and k-nearest neighbors algorithms, along with neural networks, may also be applicable to this type of classification problem. We will begin by instantiating these objects with default parameters for the time being, as well as define an accuracy function used to quantify our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='l2', multi_class='ovr')\n",
    "forest_classifier = RandomForestClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    predictions = estimator.predict(X)\n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, prior to testing our algorithms, we must address the fact that only one label sample is present for every ten acceleration samples. For an initial naive method, we can extract only the X samples corresponding to the timestamps in the Y data, but it is possible that we can better estimate the label using the information we are currently ignoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20589</td>\n",
       "      <td>1565109931087</td>\n",
       "      <td>2019-08-06T16:45:31.087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20599</td>\n",
       "      <td>1565109932090</td>\n",
       "      <td>2019-08-06T16:45:32.090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20609</td>\n",
       "      <td>1565109933092</td>\n",
       "      <td>2019-08-06T16:45:33.092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20619</td>\n",
       "      <td>1565109934094</td>\n",
       "      <td>2019-08-06T16:45:34.094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20629</td>\n",
       "      <td>1565109935097</td>\n",
       "      <td>2019-08-06T16:45:35.097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>24289</td>\n",
       "      <td>1565110302030</td>\n",
       "      <td>2019-08-06T16:51:42.030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>24299</td>\n",
       "      <td>1565110303032</td>\n",
       "      <td>2019-08-06T16:51:43.032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>24309</td>\n",
       "      <td>1565110304034</td>\n",
       "      <td>2019-08-06T16:51:44.034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>24319</td>\n",
       "      <td>1565110305037</td>\n",
       "      <td>2019-08-06T16:51:45.037</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>24329</td>\n",
       "      <td>1565110306039</td>\n",
       "      <td>2019-08-06T16:51:46.039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      timestamp                 UTC time  label\n",
       "0         20589  1565109931087  2019-08-06T16:45:31.087      1\n",
       "1         20599  1565109932090  2019-08-06T16:45:32.090      1\n",
       "2         20609  1565109933092  2019-08-06T16:45:33.092      1\n",
       "3         20619  1565109934094  2019-08-06T16:45:34.094      1\n",
       "4         20629  1565109935097  2019-08-06T16:45:35.097      1\n",
       "..          ...            ...                      ...    ...\n",
       "370       24289  1565110302030  2019-08-06T16:51:42.030      4\n",
       "371       24299  1565110303032  2019-08-06T16:51:43.032      4\n",
       "372       24309  1565110304034  2019-08-06T16:51:44.034      4\n",
       "373       24319  1565110305037  2019-08-06T16:51:45.037      4\n",
       "374       24329  1565110306039  2019-08-06T16:51:46.039      4\n",
       "\n",
       "[375 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565109931087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565109932090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565109933092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565109934094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565109935097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1565110302030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1565110303032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1565110304034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1565110305037</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1565110306039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  label\n",
       "0    1565109931087      1\n",
       "1    1565109932090      1\n",
       "2    1565109933092      1\n",
       "3    1565109934094      1\n",
       "4    1565109935097      1\n",
       "..             ...    ...\n",
       "370  1565110302030      4\n",
       "371  1565110303032      4\n",
       "372  1565110304034      4\n",
       "373  1565110305037      4\n",
       "374  1565110306039      4\n",
       "\n",
       "[375 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y = train_Y.loc[:, ['timestamp', 'label']]\n",
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565109931087</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.987701</td>\n",
       "      <td>0.068985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1565109932090</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>-0.852371</td>\n",
       "      <td>-0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1565109933092</td>\n",
       "      <td>0.145584</td>\n",
       "      <td>-1.007843</td>\n",
       "      <td>-0.036819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1565109934094</td>\n",
       "      <td>-0.099380</td>\n",
       "      <td>-1.209686</td>\n",
       "      <td>0.304489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1565109935097</td>\n",
       "      <td>0.082794</td>\n",
       "      <td>-1.001434</td>\n",
       "      <td>-0.025375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>1565110302030</td>\n",
       "      <td>-0.641953</td>\n",
       "      <td>-1.469177</td>\n",
       "      <td>0.301041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>1565110303032</td>\n",
       "      <td>-0.171616</td>\n",
       "      <td>-0.366074</td>\n",
       "      <td>-0.059082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>1565110304034</td>\n",
       "      <td>0.401810</td>\n",
       "      <td>-1.077698</td>\n",
       "      <td>0.258911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>1565110305037</td>\n",
       "      <td>0.330338</td>\n",
       "      <td>-1.470062</td>\n",
       "      <td>0.303894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>1565110306039</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>-0.991043</td>\n",
       "      <td>0.034973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp         x         y         z\n",
       "3     1565109931087 -0.053802 -0.987701  0.068985\n",
       "13    1565109932090  0.013718 -0.852371 -0.000870\n",
       "23    1565109933092  0.145584 -1.007843 -0.036819\n",
       "33    1565109934094 -0.099380 -1.209686  0.304489\n",
       "43    1565109935097  0.082794 -1.001434 -0.025375\n",
       "...             ...       ...       ...       ...\n",
       "3703  1565110302030 -0.641953 -1.469177  0.301041\n",
       "3713  1565110303032 -0.171616 -0.366074 -0.059082\n",
       "3723  1565110304034  0.401810 -1.077698  0.258911\n",
       "3733  1565110305037  0.330338 -1.470062  0.303894\n",
       "3743  1565110306039  0.689346 -0.991043  0.034973\n",
       "\n",
       "[375 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_subset = train_X.iloc[[train_X.timestamp[i] in train_Y.timestamp.values for i in range(len(train_X.timestamp))], :]\n",
    "print(all(train_X_subset.timestamp.values==train_Y.timestamp.values))\n",
    "train_X_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another modification necessary is to extract only the values of the relevant columns. We will do this using the iloc subsetting method and the .values attribute for both X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_X_subset.iloc[:, 1:].values\n",
    "Y = train_Y.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the classifiers we instantiated earlier on this X and Y data. We quantify our results using the cross_val_score method from sklearn.model_builder using 10-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Average Score: 0.5736130867709817\n",
      "Random Forest Average Score: 0.9094594594594596\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logistic_scores = cross_val_score(logistic_regression, X, Y, cv=10, scoring=accuracy)\n",
    "rf_scores = cross_val_score(forest_classifier, X, Y, cv=10, scoring=accuracy)\n",
    "print(\"Logistic Regression Average Score:\", np.mean(logistic_scores))\n",
    "print(\"Random Forest Average Score:\", np.mean(rf_scores))\n",
    "\n",
    "# Plot Results\n",
    "plt.axes().set_aspect('equal', 'box')\n",
    "plt.scatter(logistic_scores, rf_scores)\n",
    "plt.plot((0, 1), (0, 1), 'k-')\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Logistic Regression Score\")\n",
    "plt.ylabel(\"Forest Classifier Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show that the random forest classifier performs better than the logistic regression classifier. We can now vary some parameters in each classifier to see if we can improve the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class='ovr', max_iter = 10000, tol=0.000001)\n",
    "forest_classifier = RandomForestClassifier(max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Average Score: 0.5788051209103842\n",
      "Random Forest Average Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "logistic_scores = cross_val_score(logistic_regression, X, Y, cv=10, scoring=accuracy)\n",
    "rf_scores = cross_val_score(forest_classifier, X, Y, cv=10, scoring=accuracy)\n",
    "print(\"Logistic Regression Average Score:\", np.mean(logistic_scores))\n",
    "print(\"Random Forest Average Score:\", np.mean(rf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, even without regularization and with much higher maximal iteration and smaller tolerance, the random forest classifier still outperforms the logistic regression one-vs-all classifier. It is possible that the RF classifier is overfitting the data, but given our use of cross-validation, this is unlikely. We can perform a more systematic depth search for the random forest classifier as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Cross-Validation Score for 3 Validation Sets')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 30, 30, endpoint=True)\n",
    "score = []\n",
    "for max_depth in max_depths:\n",
    "    forest_classifier = RandomForestClassifier(max_depth=max_depth)\n",
    "    rf_scores = cross_val_score(forest_classifier, X, Y, cv=10, scoring=accuracy)\n",
    "    score.append(np.mean(rf_scores))\n",
    "plt.plot(max_depths, score)\n",
    "plt.xlabel('Max Depth Parameter')\n",
    "plt.ylabel('Mean Cross-Validation Score for 3 Validation Sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see than any value of max_depth greater than ~7 appears to give us perfect cross-validation accuracy. While we appear to be able to reliably predict activity with a random forest classifier, we are still throwing away 90% of the data through our subsetting of the train_X dataset. It may be possible to use neighboring points with a sliding-window approach to estimate labels based not only on the immediate x, y, and z acceleration, but also nearby points. For example, we can average the five nearest points (i.e. 2 before and 2 after each data point with a matching timestamp in Y) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04573364, -0.99911804,  0.12687073],\n",
       "       [-0.03197632, -0.99451599,  0.06184387],\n",
       "       [ 0.12408447, -1.0053833 , -0.02505188],\n",
       "       ...,\n",
       "       [ 0.10877991, -0.95152588,  0.18502808],\n",
       "       [ 0.40496216, -1.11669922,  0.06250916],\n",
       "       [ 0.40888977, -0.92079163,  0.04049683]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_avg = []\n",
    "for i in train_X_subset.index:\n",
    "    X_avg.append(np.mean(train_X.iloc[i-2:i+3, 1:], axis = 0))\n",
    "X_avg = np.array(X_avg)\n",
    "X_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class='ovr', max_iter = 10000, tol=0.000001)\n",
    "forest_classifier = RandomForestClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Average Score: 0.5946657183499289\n",
      "Random Forest Average Score: 0.9893314366998578\n"
     ]
    }
   ],
   "source": [
    "logistic_scores = cross_val_score(logistic_regression, X_avg, Y, cv=10, scoring=accuracy)\n",
    "rf_scores = cross_val_score(forest_classifier, X_avg, Y, cv=10, scoring=accuracy)\n",
    "print(\"Logistic Regression Average Score:\", np.mean(logistic_scores))\n",
    "print(\"Random Forest Average Score:\", np.mean(rf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the neighboring two nearest points to each recorded timepoint, we can see that the logistic regression cross_validation score increases around 2%. Changing the multiclass method from one-vs-all to multinomial does not appear to have a significant improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Average Score: 0.5972972972972973\n",
      "Random Forest Average Score: 0.9785917496443812\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class='multinomial', max_iter = 10000, tol=0.000001)\n",
    "forest_classifier = RandomForestClassifier(max_depth=5)\n",
    "logistic_scores = cross_val_score(logistic_regression, X_avg, Y, cv=10, scoring=accuracy)\n",
    "rf_scores = cross_val_score(forest_classifier, X_avg, Y, cv=10, scoring=accuracy)\n",
    "print(\"Logistic Regression Average Score:\", np.mean(logistic_scores))\n",
    "print(\"Random Forest Average Score:\", np.mean(rf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we can do better with a systematic search. Let's vary this weighting window from 0 to 5 in either direction, removing the last sample and the first if the boundary goes beyond the endpoints of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean cross-validation score')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class='ovr', max_iter = 10000, tol=0.000001)\n",
    "forest_classifier = RandomForestClassifier(max_depth=7)\n",
    "\n",
    "scores_lr = []\n",
    "scores_rf = []\n",
    "for depth in range(6):\n",
    "    X_avg = []\n",
    "    if depth > 3:\n",
    "        for i in train_X_subset.index[1:-1]:\n",
    "            X_avg.append(np.mean(train_X.iloc[i-depth:i+depth+1, 1:], axis = 0))\n",
    "        Y_subset = Y[1:-1]\n",
    "    else:\n",
    "        for i in train_X_subset.index[:-1]:\n",
    "            X_avg.append(np.mean(train_X.iloc[i-depth:i+depth+1, 1:], axis = 0))\n",
    "        Y_subset = Y[:-1]\n",
    "    X_avg = np.array(X_avg)\n",
    "    \n",
    "    logistic_scores = cross_val_score(logistic_regression, X_avg, Y_subset, cv=10, scoring=accuracy)\n",
    "    rf_scores = cross_val_score(forest_classifier, X_avg, Y_subset, cv=10, scoring=accuracy)\n",
    "    \n",
    "    scores_lr.append(np.mean(logistic_scores))\n",
    "    scores_rf.append(np.mean(rf_scores))\n",
    "\n",
    "plt.plot(range(6), scores_lr, label=\"logistic regression\")\n",
    "plt.plot(range(6), scores_rf, label=\"random forest\")\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighboring points used in average')\n",
    "plt.ylabel('Mean cross-validation score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, we see that the RF classifier appears to be unaffected by our modification of the data, while the logistic regression classifier increases to an accuracy around 0.7 and levels off. Further changes to the methodology could include the use of weighted averages rather than simple averages. Let's next explore the use of an exponentially weighted average, wherein we initialize the EWA at 0 and update it at each sample of x as $EWA := \\beta * EWA + (1-\\beta) * X_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.48498535e-04, -9.34860229e-02, -6.90460205e-03],\n",
       "       [-7.23037720e-03, -1.85681610e-01,  2.74124146e-03],\n",
       "       [-1.08560944e-02, -2.69238998e-01,  2.03137970e-02],\n",
       "       ...,\n",
       "       [ 3.41590478e-01, -1.02719481e+00,  1.06514489e-01],\n",
       "       [ 3.24219150e-01, -1.00475792e+00,  1.00843508e-01],\n",
       "       [ 3.60731866e-01, -1.00338644e+00,  9.42564721e-02]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewa = []\n",
    "ewa = np.array([0, 0, 0])\n",
    "beta = 0.9\n",
    "for i in range(len(train_X)):\n",
    "    ewa = beta * ewa + (1-beta) * train_X.iloc[i, 1:]\n",
    "    X_ewa.append(ewa)\n",
    "X_ewa = np.array(X_ewa)\n",
    "X_ewa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ewa_subset = X_ewa[[train_X.timestamp[i] in train_Y.timestamp.values for i in range(len(train_X.timestamp))], :]\n",
    "X_ewa_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After subsetting this average to the matching data points, we can test it on our algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Average Score: 0.7467994310099574\n",
      "Random Forest Average Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class='ovr', max_iter = 10000, tol=0.000001)\n",
    "forest_classifier = RandomForestClassifier(max_depth=7)\n",
    "\n",
    "logistic_scores = cross_val_score(logistic_regression, X_ewa_subset, Y, cv=10, scoring=accuracy)\n",
    "rf_scores = cross_val_score(forest_classifier, X_ewa_subset, Y, cv=10, scoring=accuracy)\n",
    "print(\"Logistic Regression Average Score:\", np.mean(logistic_scores))\n",
    "print(\"Random Forest Average Score:\", np.mean(rf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method appears to further improve our cross-validation accuracy on the logistic model. Given that the random forest is consistently performing much better than the logistic regression model, let's continue only with the random forest and explore some hyperparameter dependencies, such as the min_samples_leaf and min_samples_split parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Score: 0.9275960170697013\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier(max_depth=7, min_samples_leaf = 2, min_samples_split=3)\n",
    "rf_scores = cross_val_score(forest_classifier, X_ewa_subset, Y, cv=10, scoring=accuracy)\n",
    "print(\"Random Forest Average Score:\", rf_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Score: 0.909317211948791\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier(max_depth=7, min_samples_leaf = 2, min_samples_split=3)\n",
    "rf_scores = cross_val_score(forest_classifier, X, Y, cv=10, scoring=accuracy)\n",
    "print(\"Random Forest Average Score:\", rf_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Score: 0.9251066856330015\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier(max_depth=11, min_samples_leaf = 2, min_samples_split=3)\n",
    "rf_scores = cross_val_score(forest_classifier, X_ewa_subset, Y, cv=10, scoring=accuracy)\n",
    "print(\"Random Forest Average Score:\", rf_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Score: 0.9090327169274538\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier(max_depth=11, min_samples_leaf = 2, min_samples_split=3)\n",
    "rf_scores = cross_val_score(forest_classifier, X, Y, cv=10, scoring=accuracy)\n",
    "print(\"Random Forest Average Score:\", rf_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that above some threshold, there does not seem to be a substantial improvement from increasing the max_depth. However, it appears that preventing the tree from making more splits by placing more stringent requirements on the splitting parameters decreases the accuracy. Therefore, it is possible that we may be slightly overfitting the data, since this could indicate that there is a single leaf for each data point, despite our use of cross-validation. If we look back at our experimental data, we see the following distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "213\n",
      "88\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(sum(Y == 1))\n",
    "print(sum(Y == 2))\n",
    "print(sum(Y == 3))\n",
    "print(sum(Y == 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, class 2 (walking) is by far the most abundant. With this skewed class distribution, using the balanced_accuracy measure may be more applicable to our data than conventional accuracy. Let's perform a systematic parameter search with this new accuracy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    predictions = estimator.predict(X)\n",
    "    return balanced_accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': range(1, 15),\n",
       "                         'min_samples_leaf': range(1, 6),\n",
       "                         'min_samples_split': range(2, 7)},\n",
       "             scoring=<function balanced_accuracy at 0x0000023D7DA38730>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': range(1, 15),\n",
    "    'min_samples_leaf': range(1, 6),\n",
    "    'min_samples_split': range(2, 7)\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(), param_grid=params, scoring=balanced_accuracy, cv=10)\n",
    "rf.fit(X_ewa_subset, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at our results. Specifically, we'll focus on the mean_test_score parameter of cv_results_. We'll also reshape the (350,) array to a (14, 5, 5) array to make interpretation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.3375     0.32057449 0.33414141 0.33897727 0.3261553 ]\n",
      "  [0.32171086 0.32682449 0.35050505 0.33657197 0.31729167]\n",
      "  [0.34668561 0.34212753 0.33022727 0.33629419 0.32337753]\n",
      "  [0.35025253 0.34189394 0.33747475 0.33247475 0.33247475]\n",
      "  [0.34580808 0.34080808 0.34001894 0.32724116 0.33876894]]\n",
      "\n",
      " [[0.54757846 0.55163149 0.58238005 0.57118957 0.53452291]\n",
      "  [0.53132846 0.50871483 0.52079816 0.57046988 0.47577291]\n",
      "  [0.46822872 0.47431457 0.46299513 0.46822872 0.49021735]\n",
      "  [0.42264791 0.43667569 0.44598124 0.42799513 0.44098124]\n",
      "  [0.39015783 0.41132846 0.40285624 0.40375902 0.39688402]]\n",
      "\n",
      " [[0.78249008 0.7872123  0.78125902 0.75420094 0.70496483]\n",
      "  [0.72042569 0.70350649 0.72420094 0.72756854 0.69654221]\n",
      "  [0.60993957 0.61334235 0.58612013 0.58445346 0.62334235]\n",
      "  [0.47910624 0.4581241  0.48445346 0.49612013 0.50056457]\n",
      "  [0.41104076 0.41931457 0.40723124 0.39618957 0.41431457]]\n",
      "\n",
      " [[0.88582341 0.88769841 0.87492063 0.85183983 0.78867965]\n",
      "  [0.86556457 0.83482594 0.83898268 0.82238546 0.73044102]\n",
      "  [0.64223124 0.63438402 0.63056457 0.63018218 0.6584118 ]\n",
      "  [0.56521735 0.52799513 0.50223124 0.47987013 0.50000902]\n",
      "  [0.40847132 0.41000902 0.41159632 0.42608496 0.4065368 ]]\n",
      "\n",
      " [[0.96916667 0.95242063 0.92947872 0.87090188 0.85678571]\n",
      "  [0.87423521 0.85454816 0.88638799 0.83016324 0.75659632]\n",
      "  [0.62776154 0.6594688  0.67951299 0.63919102 0.63558983]\n",
      "  [0.51458243 0.47132846 0.48215188 0.49632846 0.50132846]\n",
      "  [0.40632846 0.41069354 0.42180465 0.39791576 0.44405213]]\n",
      "\n",
      " [[0.995      0.98131944 0.94645833 0.89796627 0.86078824]\n",
      "  [0.86531205 0.89093705 0.87894841 0.85742965 0.80889791]\n",
      "  [0.66928932 0.65813402 0.62223124 0.64500902 0.66757846]\n",
      "  [0.52396735 0.49908099 0.49556457 0.48167569 0.49879329]\n",
      "  [0.41791576 0.4052868  0.42236021 0.4165368  0.42433983]]\n",
      "\n",
      " [[1.         1.         0.965      0.89671627 0.87518849]\n",
      "  [0.87850649 0.8563438  0.88302038 0.82914051 0.80722132]\n",
      "  [0.64917569 0.63681457 0.64851551 0.62268218 0.65764791]\n",
      "  [0.51521735 0.54241432 0.47855069 0.4920671  0.49000902]\n",
      "  [0.42799513 0.40688402 0.41987013 0.3996618  0.42542569]]\n",
      "\n",
      " [[1.         1.         0.94741071 0.91970238 0.88421627]\n",
      "  [0.86521735 0.85599657 0.88850649 0.83694354 0.80869499]\n",
      "  [0.68378427 0.64292569 0.6763438  0.70570346 0.67560877]\n",
      "  [0.55112013 0.52945346 0.52612013 0.48243957 0.49889791]\n",
      "  [0.43410624 0.41188402 0.40746483 0.4177868  0.43040584]]\n",
      "\n",
      " [[1.         0.98875    0.97859127 0.89768849 0.87985119]\n",
      "  [0.89292569 0.8684623  0.87690927 0.84829816 0.80930465]\n",
      "  [0.65334235 0.60980069 0.65570346 0.6943741  0.62720599]\n",
      "  [0.48910624 0.48715188 0.51408099 0.49632846 0.47945346]\n",
      "  [0.42299513 0.40875902 0.41632846 0.41748377 0.41040043]]\n",
      "\n",
      " [[0.99375    0.9875     0.96916667 0.93933983 0.84992965]\n",
      "  [0.89155213 0.8710561  0.8550496  0.85099657 0.80268218]\n",
      "  [0.65334235 0.66301046 0.66227543 0.69241432 0.63283099]\n",
      "  [0.51215188 0.52889791 0.50264791 0.50743957 0.48487013]\n",
      "  [0.42223124 0.40756854 0.43632846 0.39785624 0.42855069]]\n",
      "\n",
      " [[1.         1.         0.97034722 0.93423611 0.87791667]\n",
      "  [0.86407738 0.87065927 0.88257846 0.85714196 0.81583243]\n",
      "  [0.65093705 0.66986021 0.67854076 0.66505321 0.67396735]\n",
      "  [0.50521735 0.49079816 0.5077868  0.51604076 0.53181457]\n",
      "  [0.41118957 0.44188402 0.41320346 0.42180465 0.41521735]]\n",
      "\n",
      " [[1.         0.99375    0.97131944 0.91370491 0.8744246 ]\n",
      "  [0.87855069 0.87746483 0.87177038 0.85266324 0.78507846]\n",
      "  [0.63980069 0.65473124 0.65671988 0.6314926  0.65255321]\n",
      "  [0.48209235 0.49157107 0.50003427 0.50334235 0.52556457]\n",
      "  [0.41402688 0.4146618  0.4065368  0.39944354 0.41709235]]\n",
      "\n",
      " [[1.         1.         0.97381944 0.90454816 0.88268218]\n",
      "  [0.87527688 0.88138889 0.89218705 0.8487491  0.77909632]\n",
      "  [0.6608676  0.63305465 0.64452291 0.64688402 0.66330718]\n",
      "  [0.47056457 0.50881854 0.46521735 0.47857594 0.51132846]\n",
      "  [0.42577291 0.4146618  0.39285624 0.4046618  0.40598124]]\n",
      "\n",
      " [[1.         0.98875    0.95387897 0.91724657 0.8677426 ]\n",
      "  [0.89960768 0.86719246 0.88290675 0.83988546 0.80145743]\n",
      "  [0.66250902 0.67084235 0.62000902 0.66048521 0.68621483]\n",
      "  [0.52834235 0.51188402 0.48799513 0.48875902 0.48665043]\n",
      "  [0.40243957 0.4196618  0.41243957 0.42051046 0.41347132]]]\n"
     ]
    }
   ],
   "source": [
    "res = rf.cv_results_['mean_test_score'].reshape(14,5,5)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the parameter combinations which gave us maximal cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:\n",
      "\n",
      "[7, 7, 8, 8, 9, 11, 11, 12, 13, 13, 14]\n",
      "\n",
      "\n",
      "Leaf:\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "Split:\n",
      "\n",
      "[2, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = rf.cv_results_['mean_test_score'] == 1\n",
    "depth = []\n",
    "leaf = []\n",
    "split = []\n",
    "for i,val in enumerate(idx):\n",
    "    if val:\n",
    "        depth.append(rf.cv_results_['param_max_depth'][i])\n",
    "        leaf.append(rf.cv_results_['param_min_samples_leaf'][i])\n",
    "        split.append(rf.cv_results_['param_min_samples_split'][i])\n",
    "print(\"Depth:\\n\")\n",
    "print(depth)\n",
    "print('\\n')\n",
    "print(\"Leaf:\\n\")\n",
    "print(leaf)\n",
    "print('\\n')\n",
    "print(\"Split:\\n\")\n",
    "print(split)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these values, we can tell that depths above 7, samples/leaf of 1, and minimum number of samples required to split of 2 or 3 provides optimal cross-validation performance. With this in mind, we can construct our final model and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier(max_depth=11, min_samples_leaf = 1, min_samples_split=2)\n",
    "forest_classifier.fit(X_ewa_subset, Y)\n",
    "accuracy_score(forest_classifier.predict(X_ewa_subset), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our final model architecture selected and trained, we'll now re-run all the relevant pieces of code, i.e. importing libraries and initial data, subsetting, and model training. We'll also have to convert the training data to an exponentially-weighted average before using our fitted model to predict the labels. We'll use the time module to time the total runtime of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Total runtime:  0:00:02.739975\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "tic = datetime.now()\n",
    "train_X = pd.read_csv('train_time_series.csv')\n",
    "train_X = train_X.iloc[:, [1, 4, 5, 6]]\n",
    "train_Y = pd.read_csv('train_labels.csv')\n",
    "train_Y = train_Y.loc[:, ['timestamp', 'label']]\n",
    "test_X = pd.read_csv('test_time_series.csv')\n",
    "Y = train_Y.label.values\n",
    "X_ewa = []\n",
    "ewa = np.array([0, 0, 0])\n",
    "beta = 0.9\n",
    "for i in range(len(train_X)):\n",
    "    ewa = beta * ewa + (1-beta) * train_X.iloc[i, 1:]\n",
    "    X_ewa.append(ewa)\n",
    "X_ewa = np.array(X_ewa)\n",
    "X_ewa_subset = X_ewa[[train_X.timestamp[i] in train_Y.timestamp.values for i in range(len(train_X.timestamp))], :]\n",
    "\n",
    "forest_classifier = RandomForestClassifier(max_depth=11, min_samples_leaf = 1, min_samples_split=2)\n",
    "forest_classifier.fit(X_ewa_subset, Y)\n",
    "\n",
    "test_X = test_X.iloc[:, -3:]\n",
    "X_ewa_test = []\n",
    "ewa = np.array([0, 0, 0])\n",
    "for i in range(len(test_X)):\n",
    "    ewa = beta * ewa + (1-beta) * test_X.iloc[i, :]\n",
    "    X_ewa_test.append(ewa)\n",
    "X_ewa_test = np.array(X_ewa_test)\n",
    "predictions = forest_classifier.predict(X_ewa_test)\n",
    "toc = datetime.now()\n",
    "\n",
    "print(\"Total runtime: \", toc-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, our code runs in 2.7 seconds. Given that we don't have the true labels for our testing set, it is difficult to quantify our final model performance. Even so, use of 10-fold cross-validation provides evidence that the model should perform well on the testing data. Certain improvements could still potentially be made to reduce total runtime. For example, using the exponentially weighted average did not appear to significantly improve model performance beyond data included in the instantaneous triaxial accelerations. Therefore, to reduce needed computation and data modification, it may not be necessary to use this methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last remark, lets examine the distribution of our predictions and compare that to the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "666\n",
      "287\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print(sum(predictions == 1))\n",
    "print(sum(predictions == 2))\n",
    "print(sum(predictions == 3))\n",
    "print(sum(predictions == 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.666666666666667\n",
      "3.1267605633802815\n",
      "3.2613636363636362\n",
      "3.0638297872340425\n"
     ]
    }
   ],
   "source": [
    "print(sum(predictions == 1)/sum(Y==1))\n",
    "print(sum(predictions == 2)/sum(Y==2))\n",
    "print(sum(predictions == 3)/sum(Y==3))\n",
    "print(sum(predictions == 4)/sum(Y==4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1224\n",
      "0.5328\n",
      "0.2296\n",
      "0.1152\n"
     ]
    }
   ],
   "source": [
    "print(sum(predictions == 1)/len(predictions))\n",
    "print(sum(predictions == 2)/len(predictions))\n",
    "print(sum(predictions == 3)/len(predictions))\n",
    "print(sum(predictions == 4)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.072\n",
      "0.568\n",
      "0.23466666666666666\n",
      "0.12533333333333332\n"
     ]
    }
   ],
   "source": [
    "print(sum(Y == 1)/len(Y))\n",
    "print(sum(Y == 2)/len(Y))\n",
    "print(sum(Y == 3)/len(Y))\n",
    "print(sum(Y == 4)/len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this qualitative similarity, it certainly seems possible that our training and testing data was drawn from the same distribution, suggesting that our model accuracy may be high as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
